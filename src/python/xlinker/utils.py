"""Utility functions for PECOS-EL models"""
import os
"""
from pecos.xmc import Indexer, LabelEmbeddingFactory
from pecos.utils.cluster_util import ClusterChain
from pecos.utils import smat_util
from pecos.utils.featurization.text.preprocess import Preprocessor
from pecos.utils.cluster_util import ClusterChain
from pecos.xmc.xtransformer.model import XTransformer
"""
from src.python.utils import parse_json, parse_dataset, add_predicted_kb_identifers
from src.python.kbs import KnowledgeBase
from src.python.xlinker.candidates import map_to_kb, output_candidates_file


def get_cluster_chain(
    X=None, X_feat=None, Y=None, method="", cluster_chain_filepath="", Z_filepath=""
):
    """
    Generate a Hierarchical label tree that corresponds to the component
    semantic label indexing in the PECOS-EL model.

    Parameters
    ----------
    X : lst of str
        Parsed training instances
    X_feat : csr_matrix
        Training feature matrix. Training instances features generated by the TF-IDF model.
    Y : csr_matrix
        The label matrix including the labels associated with training instances.
    method : str
        The method to use for clustering: PIFA (Positive Instance Feature 
        Aggregation) or PIFA + LF (Label Representation via Label Features 
        in addition to PIFA).
    cluster_chain_filepath : str
        The path to save the cluster chain.
    Z_filepath : str
        The path to the external label embeddings.

    Returns
    -------
    cluster_chain : class representing a hierarchical clustering as a list of CSC matrices

    """

    if os.path.exists(cluster_chain_filepath):
        cluster_chain = ClusterChain.load(cluster_chain_filepath)

    else:
        #Generate a new cluster chain

        if method == "pifa":
            #PIFA: Positive Instance Feature Aggregation
            label_feat = LabelEmbeddingFactory.create(
                Y=Y, X=X_feat, method="pifa", threads=30, normalized_Y=True
            )

        elif method == "pifa_lf":
            # METHOD: PIFA + LF ->  Create label embedding by
            # concatenating pifa embeddings and provided existing
            # label embedding generated externally.

            # # Load external KB/Label features/embeddings
            Z_feat = smat_util.load_matrix(Z_filepath)
            print(label_feat.shape)
            print(X_feat.shape, Y.shape, Z_feat.shape)

            label_feat = LabelEmbeddingFactory.create(
                Y=Y,
                X=X_feat,
                Z=Z_feat.toarray(),
                method="pifa_lf_concat",
                threads=30,
                normalized_Y=True,
            )

        cluster_chain = Indexer.gen(label_feat)
        cluster_chain.save(cluster_chain_filepath)

    return cluster_chain


def load_model(model_dir, clustering_method="pifa"):
    """
    Load a PECOS-EL model from disk.
    """
    custom_xtf = XTransformer.load(f"{model_dir}/xtransformer")
    tfidf_model = Preprocessor.load(f"{model_dir}/tfidf_model")
    cluster_chain = ClusterChain.load(f"{model_dir}/cluster_chain_{clustering_method}")

    return custom_xtf, tfidf_model, cluster_chain


def lower_dict_keys(input_dict):
    """
    Convert the keys of a dictionary to lowercase.
    """
    return {k.lower(): v for k, v in input_dict.items()}


def lower_list(input_list):
    """
    Convert a list of strings to lowercase.
    """
    return [item.lower() for item in input_list]


def load_kb_info(kb, inference=False):
    """
    Load the information of a knowledge base from disk (generated mappings 
    in JSON format) to be used in the PECOS-EL model.
    """

    data_dir = f"data/kbs/{kb}"

    with open(f"{data_dir}/labels.txt", "r", encoding="utf-8") as fin:
        labels = [ll.strip() for ll in fin.readlines()]
        fin.close()

    # Open mappings label to name
    label_2_name = parse_json(f"{data_dir}/label_2_name.json")
    index_2_label = parse_json(f"{data_dir}/index_2_label.json")

    if inference:
        name_2_label = parse_json(f"{data_dir}/name_2_label.json")
        synonym_2_label = parse_json(f"{data_dir}/synonym_2_label.json")
        kb_names = lower_list(name_2_label.keys())
        kb_synonyms = lower_list(synonym_2_label.keys())
        name_2_label_lower = lower_dict_keys(name_2_label)
        synonym_2_label_lower = lower_dict_keys(synonym_2_label)

        return (
            label_2_name,
            index_2_label,
            synonym_2_label_lower,
            name_2_label_lower,
            kb_names,
            kb_synonyms,
        )

    else:
        return labels, label_2_name, index_2_label


def load_kb_object(kb):
    """
    Load knowledge base object.
    """

    return KnowledgeBase(kb=kb, input_format="tsv")


def process_predictions(
    output, annotations, entity_type, labels=None, label_2_name=None
):
    """
    Process the predictions of the PECOS-EL model into a dictionary.

    Parameters
    ----------
    output : csr_matrix
        The output of the PECOS-EL model.
    annotations : list of lists
        A list of lists containing the annotations for each document.
    entity_type : str
        The type of entity being annotated.
    labels : list of str, optional
        A list of labels for the entities. Default is None.
    label_2_name : dict of str to str, optional
        A dictionary mapping labels to entity names. Default is None.

    Returns
    -------
    doc_out : dict
        A dictionary containing the predictions for each document.
    """

    doc_out = {}

    for i in range(len(annotations)):
        pred_index = output[i, :].indices[0]  # -1
        pred_label = labels[pred_index]
        key = str(i)
        doc_out[key] = (pred_label, entity_type)

    return doc_out


def retrieve_candidates_list(
    predictions=None,
    doc_annotations=None,
    index_2_label=None,
    label_2_name=None,
    kb_obj=None,
    top_k=None,
    threshold=0.10,
):
    """
    Process the predictions of the PECOS-EL model to generate a list of
    the top K candidates for each annotation in the input.
    """
    doc_preds = {}

    for i, annot in enumerate(doc_annotations):
        start = annot[0]
        end = annot[1]
        ent_text = annot[2]
        doc_preds[str(i)] = []

        pred_indexes = predictions[i, :].indices.tolist()

        top_cand_score = predictions[i, :].data[0]
        top_cand_label = index_2_label[f"{pred_indexes[0]}"]
        top_cand_text = label_2_name[top_cand_label]
        search_key = str(i)
        doc_preds[search_key].append(
            (start, end, top_cand_text, top_cand_label, top_cand_score)
        )

        if top_cand_score < threshold:
            del doc_preds[search_key][0]

            # complete candidates list with candidates retrived by string matching
            matches = map_to_kb(ent_text, kb_obj.name_2_id, kb_obj.synonym_2_id, 1)

            for match in matches:
                doc_preds[search_key].append(
                    (start, end, match["name"], match["kb_id"], match["score"])
                )

    return doc_preds


def process_pecos_preds(
    annotation, mention_preds, index_2_label, top_k, inference=False, label_2_name=None):
    """
    Process the predictions of the PECOS-EL model for a given mention.
    
    Parameters
    ----------
    annotation : list
        A list containing the annotation information for the mention.
    mention_preds : csr_matrix
        The predictions of the PECOS-EL model for the mention.
    index_2_label : dict
        A dictionary mapping indices to labels.
    top_k : int
        The number of top-k predictions to return.
    inference : bool, optional
        A flag to indicate if the function is being used for inference. 
        Default is False.
    label_2_name : dict, optional
        A dictionary mapping labels to entity names. Default is None.
    """

    # Add all X-Linker predictions
    pred_labels = []
    pred_scores = []

    for k in range(top_k):
        pred_score = float(mention_preds.data[k])
        pred_scores.append(pred_score)
        pred_index = mention_preds.indices[k]
        pred_label = index_2_label[str(pred_index)]
        pred_labels.append(pred_label)

    if inference:
        output = []
        pred_names = [label_2_name[label] for label in pred_labels]

        for name, label, score in zip(pred_names, pred_labels, pred_scores):
            output.append((name, label, score))
        
        return output

    else:
        return [
            annotation[0],
            annotation[1],
            annotation[2],
            annotation[3],
            annotation[4],
            pred_labels,
            pred_scores,
        ]


def apply_pipeline_to_mention(
    input_text,
    annotation,
    mention_preds,
    kb_names,
    kb_synonyms,
    name_2_id,
    synonym_2_id,
    index_2_label,
    top_k=1,
    fuzzy_top_k=1,
    threshold=0.15,
):
    """
    Apply X-Linker pipeline to given input mention. The pipeline includes
    the string matcher and the processing of the output of PECOS-EL model.

    Parameters
    ----------
    input_text : str
        The input text containing the mention.
    annotation : list of lists
        A list containing the annotation information for the mention, including
        doc_id, annot_start, annot_end, annot_text, annot_kb_id.
    mention_preds : csr_matrix
        The predictions of the PECOS-EL model for the mention.
    kb_names : list of str
        A list of knowledge base names.
    kb_synonyms : list of str
        A list of knowledge base synonyms.
    name_2_id : dict
        A dictionary mapping entity names to labels (aka KB identifiers).
    synonym_2_id : dict
        A dictionary mapping entity synonyms to labels (aka KB identifiers).
    index_2_label : dict
        A dictionary mapping indices to labels. Each KB entity has name, 
        label (or identifier) and an index.
    top_k : int
        The number of top-k predictions to return. Default is 1.
    fuzzy_top_k : int
        The number of top-k fuzzy matches to return. Default is 1.
    threshold : float
        The threshold for the prediction score. Default is 0.15.

    Returns
    -------
    output : list
        A list containing the updated annotation information for the
        mention, including doc_id, annot_start, annot_end, annot_text, annot_kb_id,
        labels, and scores.
    """

    output = []
    annot_text = annotation[3]
    true_label = annotation[4]
    # -----------------------------------------
    #   Get exact match from KB
    # -----------------------------------------
    kb_matches = map_to_kb(
        input_text, kb_names, kb_synonyms, name_2_id, synonym_2_id, top_k=fuzzy_top_k
    )

    # -----------------------------------------------
    # Process X-Linker predictions
    # -----------------------------------------------
    pecos_output = process_pecos_preds(annotation, mention_preds, index_2_label, top_k)
    labels_to_add, scores_to_add = [], []

    if kb_matches[0]["score"] == 1.0:
        labels_to_add.append(kb_matches[0]["kb_id"])
        scores_to_add.append(kb_matches[0]["score"])

        if pecos_output[6][0] == 1.0:
            labels_to_add.append(pecos_output[5][0])
            scores_to_add.append(pecos_output[6][0])

    else:

        if pecos_output[6][0] >= threshold:
            labels_to_add.append(pecos_output[5][0])
            scores_to_add.append(pecos_output[6][0])

        else:

            for i, label in enumerate(pecos_output[5]):
                labels_to_add.append(label)
                scores_to_add.append(pecos_output[6][i])

            for i, match in enumerate(kb_matches):
                labels_to_add.append(match["kb_id"])
                scores_to_add.append(match["score"])

    output = [
        annotation[0],
        annotation[1],
        annotation[2],
        annotation[3],
        annotation[4],
        labels_to_add,
        scores_to_add,
    ]

    return output
